# Pulse CLI Environment Configuration
# Copy this file to .env and fill in your values

# ============================================
# AI Configuration (LiteLLM - Multi-Provider)
# ============================================
# LiteLLM supports multiple AI providers. Set the API key for your preferred provider.
# You only need to set ONE of the following API keys.

# Google (Gemini) - Default
# Get your key at: https://aistudio.google.com/apikey
GEMINI_API_KEY=your-gemini-api-key

# Anthropic (Claude)
# Get your key at: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-xxx

# OpenAI (GPT-4o)
# Get your key at: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-xxx

# Groq (Llama - Free tier available!)
# Get your key at: https://console.groq.com/keys
# GROQ_API_KEY=gsk_xxx

# Default AI model (LiteLLM format: provider/model)
# Options:
#   - gemini/gemini-2.0-flash (Default)
#   - gemini/gemini-2.5-flash-preview-05-20
#   - anthropic/claude-sonnet-4-20250514
#   - openai/gpt-4o
#   - groq/llama-3.3-70b-versatile (Free!)
PULSE_AI__DEFAULT_MODEL=gemini/gemini-2.0-flash

# AI temperature (0.0 - 2.0, lower = more focused, higher = more creative)
PULSE_AI__TEMPERATURE=0.7

# Maximum tokens for AI responses
PULSE_AI__MAX_TOKENS=4096

# Request timeout in seconds
PULSE_AI__TIMEOUT=120

# ============================================
# FinMind Configuration (Primary Data Source)
# ============================================

# API Token for FinMind (optional, for higher rate limits)
# Get token from https://finmindtrade.com/analysis/#/account/login
FINMIND_TOKEN=

# ============================================
# Application Settings
# ============================================

# Enable debug mode (true/false)
PULSE_DEBUG=false

# Cache TTL in seconds (default: 3600 = 1 hour)
PULSE_DATA__CACHE_TTL=3600

# Default historical data period
PULSE_DATA__DEFAULT_PERIOD=3mo
